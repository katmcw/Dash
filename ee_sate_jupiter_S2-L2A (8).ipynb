{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1588965940029,
     "user": {
      "displayName": "Encarni Medina Lopez",
      "photoUrl": "",
      "userId": "15650957561927476041"
     },
     "user_tz": -60
    },
    "id": "ZxJOrYm1byO6",
    "outputId": "c07a669f-c763-4143-c869-fbc6775fb604"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e405f8bac6ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Mount Drive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Mount Drive\n",
    "import google.colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWLePDN12TU0"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "service_account = 'encaramelo@alien-fold-235112.iam.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, '/content/drive/My Drive/Colab Notebooks/alien-fold-235112-e3ab4bc3ddd0.json')\n",
    "ee.Initialize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgdQoc7sZch0"
   },
   "outputs": [],
   "source": [
    "## Initialise system\n",
    "#import ee\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import os\n",
    "\n",
    "## Trigger the authentication flow.\n",
    "#ee.Authenticate()\n",
    "\n",
    "## Initialise the library.\n",
    "#ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3H7vr3aZch5"
   },
   "outputs": [],
   "source": [
    "# aux functions for time\n",
    "import datetime \n",
    "import time\n",
    "\n",
    "def get_timestamp(in_date):\n",
    "    utc_naive  = in_date.replace(tzinfo=None) - in_date.utcoffset()\n",
    "    timestamp = (utc_naive - datetime.datetime(1970, 1, 1)).total_seconds()\n",
    "    return (timestamp)\n",
    "\n",
    "\n",
    "def get_timestamp_utc(in_date):\n",
    "    utc_naive  = in_date.replace(tzinfo=None)\n",
    "    timestamp = (utc_naive - datetime.datetime(1970, 1, 1)).total_seconds()\n",
    "    return int(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KoRtCjUKZch-"
   },
   "outputs": [],
   "source": [
    "def fc2df(fc):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    features = fc.getInfo()['features']\n",
    "    dictarr = []\n",
    "    for f in features:\n",
    "        attr = f['properties']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = pd.DataFrame(dictarr)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61LxHGM8ZciA"
   },
   "outputs": [],
   "source": [
    "def get_image_n_box(latitude, longitude, start_time, end_time):\n",
    "  \"\"\" Returns the clippled image collection and the used box \"\"\"\n",
    "\n",
    "  point = ee.Geometry.Point([longitude,latitude]);\n",
    "  \n",
    "  S2 = ee.ImageCollection(\"COPERNICUS/S2_SR\");\n",
    "  # Filtering\n",
    "  S2TemporalFiltered = S2.filterDate(start_time,end_time);\n",
    "  S2SpatialFiltered = S2TemporalFiltered.filterBounds(point);\n",
    "  imagenes = S2SpatialFiltered.size()\n",
    "\n",
    "  # Box coordinates to reduce collection\n",
    "  x1 = longitude - 0.00058;\n",
    "  x2 = longitude + 0.00058;\n",
    "  y1 = latitude - 0.000437;\n",
    "  y2 = latitude + 0.000437;\n",
    "  box = ee.Geometry.Rectangle(x1,y1,x2,y2);\n",
    "\n",
    "  # Cutting collection to box\n",
    "  S2Clipped = S2SpatialFiltered.map(\n",
    "  lambda img : img.clip(box)\n",
    "  );\n",
    "\n",
    "  # Mean values\n",
    "  eBox = ee.Feature(box);\n",
    "  return S2Clipped, eBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDDOzJJ7ZciD"
   },
   "outputs": [],
   "source": [
    "def get_dataframes(S2Clipped, eBox):\n",
    "  \"\"\" Returns Bandas and Properties dataframe \"\"\"\n",
    "\n",
    "  mbox_image = lambda image : ee.Feature(None, image.reduceRegion(reducer=ee.Reducer.mean(), geometry=eBox.geometry())) \n",
    "  get_properties = lambda image : ee.Feature(None,ee.Dictionary({\n",
    "    \"system_index\":image.get('system:index'),\n",
    "    \"MEAN_SOLAR_AZIMUTH_ANGLE\":image.get('MEAN_SOLAR_AZIMUTH_ANGLE'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B1\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B1'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B2\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B2'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B3\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B3'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B4\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B4'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B5\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B5'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B6\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B6'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B7\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B7'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B8\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B8'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B9\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B9'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B10\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B10'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B11\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B11'),\n",
    "    \"MEAN_INCIDENCE_AZIMUTH_ANGLE_B12\":image.get('MEAN_INCIDENCE_AZIMUTH_ANGLE_B12'),\n",
    "    \"SOLAR_IRRADIANCE_B1\":image.get('SOLAR_IRRADIANCE_B1'),\n",
    "    \"SOLAR_IRRADIANCE_B2\":image.get('SOLAR_IRRADIANCE_B2'),\n",
    "    \"SOLAR_IRRADIANCE_B3\":image.get('SOLAR_IRRADIANCE_B3'),\n",
    "    \"SOLAR_IRRADIANCE_B4\":image.get('SOLAR_IRRADIANCE_B4'),\n",
    "    \"SOLAR_IRRADIANCE_B5\":image.get('SOLAR_IRRADIANCE_B5'),\n",
    "    \"SOLAR_IRRADIANCE_B6\":image.get('SOLAR_IRRADIANCE_B6'),\n",
    "    \"SOLAR_IRRADIANCE_B7\":image.get('SOLAR_IRRADIANCE_B7'),\n",
    "    \"SOLAR_IRRADIANCE_B8\":image.get('SOLAR_IRRADIANCE_B8'),\n",
    "    \"SOLAR_IRRADIANCE_B8A\":image.get('SOLAR_IRRADIANCE_B8A'),\n",
    "    \"SOLAR_IRRADIANCE_B9\":image.get('SOLAR_IRRADIANCE_B9'),\n",
    "    \"SOLAR_IRRADIANCE_B10\":image.get('SOLAR_IRRADIANCE_B10'),\n",
    "    \"SOLAR_IRRADIANCE_B11\":image.get('SOLAR_IRRADIANCE_B11'),\n",
    "    \"SOLAR_IRRADIANCE_B12\":image.get('SOLAR_IRRADIANCE_B12'),\n",
    "    \"CLOUDY_PIXEL_PERCENTAGE\":image.get('CLOUDY_PIXEL_PERCENTAGE'),\n",
    "    \"CLOUD_COVERAGE_ASSESSMENT\":image.get('CLOUD_COVERAGE_ASSESSMENT'),\n",
    "    \"REFLECTANCE_CONVERSION_CORRECTION\":image.get('REFLECTANCE_CONVERSION_CORRECTION'),\n",
    "    \"MEAN_SOLAR_ZENITH_ANGLE\":image.get('MEAN_SOLAR_ZENITH_ANGLE '),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B1\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B1'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B2\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B2'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B3\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B3'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B4\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B4'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B5\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B5'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B6\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B6'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B7\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B7'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B8\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B8'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B8A\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B8A'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B9\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B9'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B10\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B10'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B11\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B11'),\n",
    "    \"MEAN_INCIDENCE_ZENITH_ANGLE_B12\":image.get('MEAN_INCIDENCE_ZENITH_ANGLE_B12')}))  \n",
    "\n",
    "  df_bandas = fc2df(S2Clipped.map(mbox_image))\n",
    "  df_propiedades = fc2df(S2Clipped.map(get_properties))\n",
    "  return df_bandas, df_propiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LkIo2839ZciF"
   },
   "outputs": [],
   "source": [
    "def get_satellite_dataframe_row(latitude, longitude, date):\n",
    "    start_time = date.strftime(\"%Y-%m-%d\")\n",
    "    end_time = (date + datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    S2Clipped, eBox = get_image_n_box(latitude, longitude, start_time, end_time)\n",
    "    df_bandas, df_propiedades = get_dataframes(S2Clipped, eBox)\n",
    "    \n",
    "    merged = df_bandas.join(df_propiedades)\n",
    "    \n",
    "    if not merged.empty:\n",
    "        merged.sort_values(by=['system_index'],inplace=True)\n",
    "        merged=merged.tail(1) # get last\n",
    "    return merged\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmBmyy2vZciJ"
   },
   "outputs": [],
   "source": [
    "# get measurement dataframe (only csv for now)\n",
    "def load_n_process_measurements_file(file_path):\n",
    "    \"\"\" Load'n'process measurement csv and returns dataframe with rows that fall within an image. \n",
    "    Note: limited to one image per day\"\"\"\n",
    "    print(\"Opening measurement csv file '{}'\".format(file_path))\n",
    "    df_measurements = pd.read_csv(file_path, header=0)\n",
    "    df_measurements['DATE'] = [datetime.datetime.strptime(i[0:19], '%Y-%m-%d  %H:%M:%S').date() for i in df_measurements['DATETIME']]\n",
    "    df_out = pd.DataFrame(columns=df_measurements.columns.values)\n",
    "    for measurement_date in df_measurements.drop_duplicates('DATE', keep='first')['DATE']:\n",
    "        df_at_measurement_date = df_measurements.loc[df_measurements['DATE'] == measurement_date]\n",
    "        sat_timestamps = ee_get_picture_date(measurement_date,\n",
    "                                             df_at_measurement_date[\"LATITUDE\"].min(),\n",
    "                                             df_at_measurement_date[\"LATITUDE\"].max(),\n",
    "                                             df_at_measurement_date[\"LONGITUDE\"].min(),\n",
    "                                             df_at_measurement_date[\"LONGITUDE\"].max() )\n",
    "        df_temp = pd.DataFrame()\n",
    "        for sat_timestamp in sat_timestamps:\n",
    "            df_dif = df_at_measurement_date\n",
    "            df_dif['TIMESTAMP_DIFF'] = (df_at_measurement_date['TIMESTAMP'] - sat_timestamp).abs()\n",
    "            min_dif = df_dif['TIMESTAMP_DIFF'].min()\n",
    "            if min_dif < 3600:\n",
    "                df_temp = pd.concat([df_temp, df_dif[df_dif['TIMESTAMP_DIFF'] == min_dif]], axis =0)\n",
    "        if not df_temp.empty:        \n",
    "            df_temp.sort_values(by=['TIMESTAMP_DIFF'],inplace=True)\n",
    "            df_out = pd.concat([df_out, df_temp.head(1)], axis =0)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "coj9cQE0ZciL"
   },
   "outputs": [],
   "source": [
    "def timestamp_from_system_index(system_index):\n",
    "    year = int(system_index[0:4])\n",
    "    month = int(system_index[4:6])\n",
    "    day = int(system_index[6:8])\n",
    "    hour = int(system_index[9:11])\n",
    "    minutes = int(system_index[11:13])\n",
    "    return get_timestamp_utc(datetime.datetime(year, month, day, hour, minutes))\n",
    "\n",
    "\n",
    "S2 = ee.ImageCollection(\"COPERNICUS/S2\");\n",
    "def ee_get_picture_date(date, min_lat, max_lat, min_lon, max_lon):\n",
    "  box = ee.Geometry.Rectangle(min_lon,min_lat,max_lon,max_lat);\n",
    "  start_time = date.strftime(\"%Y-%m-%d\")\n",
    "  end_time = (date + datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "  S2TemporalFiltered = S2.filterDate(start_time, end_time);\n",
    "  S2SpatialFiltered = S2TemporalFiltered.filterBounds(box);\n",
    "  imagenes = S2SpatialFiltered.size()\n",
    "\n",
    "\n",
    "  get_index = lambda image : ee.Feature(None,ee.Dictionary({\n",
    "    \"system_index\":image.get('system:index')}))\n",
    "  fc = S2SpatialFiltered.map(get_index)\n",
    "  timestamps = []\n",
    "  for f in fc.getInfo()['features']:\n",
    "    attr = f['properties']['system_index']\n",
    "    if attr is not None:\n",
    "        timestamps.append(timestamp_from_system_index(attr))\n",
    "  return timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bW1RHIY1ZciP"
   },
   "outputs": [],
   "source": [
    "def process_file(input_file, output_file):\n",
    "  df_points = load_n_process_measurements_file(input_file )\n",
    "  df_output = pd.DataFrame()\n",
    "  if not df_points.empty:\n",
    "    for index, measure_row in df_points.iterrows():\n",
    "        try:\n",
    "          sat_row = get_satellite_dataframe_row(latitude=measure_row['LATITUDE'], longitude=measure_row['LONGITUDE'],date=measure_row['DATE'])\n",
    "        except:\n",
    "          print(\"get_satellite_dataframe_row failed, trying again\")\n",
    "          sat_row = get_satellite_dataframe_row(latitude=measure_row['LATITUDE'], longitude=measure_row['LONGITUDE'],date=measure_row['DATE'])\n",
    "        if not sat_row.empty:\n",
    "          merged_row = dict()\n",
    "          merged_row.update(measure_row)\n",
    "          merged_row.update(sat_row)\n",
    "          df_merged_row = pd.DataFrame.from_dict(merged_row)\n",
    "          df_output = pd.concat([df_output, df_merged_row], axis=0)   \n",
    "  if df_output.empty:\n",
    "    print(\"Warning: No valid points found in '{}\".format(input_file))\n",
    "  else:\n",
    "    df_output['TIME_DIFF'] = df_output.apply(lambda row: abs(int(timestamp_from_system_index(row['system_index']) - row['TIMESTAMP'])), axis=1)\n",
    "    df_output.sort_values(by=['TIME_DIFF'],inplace=True)\n",
    "    df_output.drop_duplicates('system_index', keep='first',inplace=True)\n",
    "\n",
    "  print(\"*** Complete. Saving file... '{}' \".format(output_file))\n",
    "  df_output.to_csv(os.path.join(output_dir,output_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26107,
     "status": "ok",
     "timestamp": 1588965965503,
     "user": {
      "displayName": "Encarni Medina Lopez",
      "photoUrl": "",
      "userId": "15650957561927476041"
     },
     "user_tz": -60
    },
    "id": "Horzcj3eZciR",
    "outputId": "70d69ceb-a53f-4a08-f462-dab2cb8f934a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "~~ Processing file 'sat_with_processed_BS_PR_CT_15AK_2017.csv' ~~\n",
      "Opening measurement csv file '/content/drive/My Drive/Colab Notebooks/processed_2017-2019/blacksea_2017-2019/processed_BS_PR_CT_15AK_2017.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Complete. Saving file... 'sat_with_processed_BS_PR_CT_15AK_2017.csv' \n",
      "2\n",
      "~~ Processing file 'sat_with_processed_BS_TS_FB_Nc1158_2017.csv' ~~\n",
      "Opening measurement csv file '/content/drive/My Drive/Colab Notebooks/processed_2017-2019/blacksea_2017-2019/processed_BS_TS_FB_Nc1158_2017.csv'\n",
      "*** Complete. Saving file... 'sat_with_processed_BS_TS_FB_Nc1158_2017.csv' \n",
      "3\n",
      "~~ Processing file 'sat_with_processed_BS_TS_FB_Nc1158_2018.csv' ~~\n",
      "Opening measurement csv file '/content/drive/My Drive/Colab Notebooks/processed_2017-2019/blacksea_2017-2019/processed_BS_TS_FB_Nc1158_2018.csv'\n",
      "*** Complete. Saving file... 'sat_with_processed_BS_TS_FB_Nc1158_2018.csv' \n",
      "4\n",
      "~~ Skipping, file 'sat_with_processed_BS_TS_MO_EUXRo01.csv' already exists.\n",
      "5\n",
      "~~ Skipping, file 'sat_with_processed_BS_TS_MO_EUXRo02.csv' already exists.\n",
      "6\n",
      "~~ Skipping, file 'sat_with_processed_BS_TS_MO_EUXRo03.csv' already exists.\n",
      "7\n",
      "~~ Skipping, file 'sat_with_processed_BS_TS_MO_VarnaBuoySURF.csv' already exists.\n",
      "8\n",
      "~~ Skipping, file 'sat_with_processed_BS_TS_TG_Balchik.csv' already exists.\n",
      "9\n",
      "~~ Skipping, file 'sat_with_processed_BS_TS_TG_Pomorie.csv' already exists.\n",
      "10\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_3901852.csv' already exists.\n",
      "11\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_3901854.csv' already exists.\n",
      "12\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_3901855.csv' already exists.\n",
      "13\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6901831.csv' already exists.\n",
      "14\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6900807.csv' already exists.\n",
      "15\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6901832.csv' already exists.\n",
      "16\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6901833.csv' already exists.\n",
      "17\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6901834.csv' already exists.\n",
      "18\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6901866.csv' already exists.\n",
      "19\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6903228.csv' already exists.\n",
      "20\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6903766.csv' already exists.\n",
      "21\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6903240.csv' already exists.\n",
      "22\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_6903271.csv' already exists.\n",
      "23\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_7900591.csv' already exists.\n",
      "24\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_7900596.csv' already exists.\n",
      "25\n",
      "~~ Skipping, file 'sat_with_processed_GL_PR_PF_7900595.csv' already exists.\n"
     ]
    }
   ],
   "source": [
    "measurements_dir = \"/content/drive/My Drive/Colab Notebooks/processed_2017-2019/blacksea_2017-2019\"\n",
    "output_dir = \"/content/drive/My Drive/Colab Notebooks/sat_with_processed_S2-L2A/blacksea_2017-2019\"\n",
    "\n",
    "j = 0\n",
    "for measurements_file_csv in os.listdir(measurements_dir):\n",
    "    j = j+1\n",
    "    print(j)\n",
    "    output_file = \"sat_with_\" + measurements_file_csv\n",
    "    if not os.path.isfile(os.path.join(output_dir,output_file)):\n",
    "        print(\"~~ Processing file '{}' ~~\".format(output_file))\n",
    "        input_file = os.path.join(measurements_dir, measurements_file_csv)\n",
    "        #process_file(input_file, output_file)\n",
    "        \n",
    "        try:\n",
    "            process_file(input_file, output_file)\n",
    "      \n",
    "        except Exception as e:\n",
    "            try:\n",
    "                print(\"! Processing file failed, trying again\")\n",
    "                print(e)\n",
    "                process_file(input_file, output_file)\n",
    "            except Exception as e1:\n",
    "                print(\"! Processing file failed again, giving up...\")\n",
    "                print(e1)\n",
    "    else:\n",
    "        print(\"~~ Skipping, file '{}' already exists.\".format(output_file))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ee_sate_jupiter_S2-L2A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
